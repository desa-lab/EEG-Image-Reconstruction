{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.patches import Rectangle\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import scipy as sp\n",
    "from PIL import Image\n",
    "from scipy.stats import pearsonr,binom,linregress\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_corr_all(ground_truth, predictions):\n",
    "    r = np.corrcoef(ground_truth, predictions)#cosine_similarity(ground_truth, predictions)#\n",
    "    r = r[:len(ground_truth), len(ground_truth):]  # rows: groundtruth, columns: predicitons\n",
    "    #print(r.shape)\n",
    "    # congruent pairs are on diagonal\n",
    "    congruents = np.diag(r)\n",
    "    #print(congruents)\n",
    "    \n",
    "    # for each column (predicition) we should count the number of rows (groundtruth) that the value is lower than the congruent (e.g. success).\n",
    "    success = r < congruents\n",
    "    success_cnt = np.sum(success, 0)\n",
    "    \n",
    "    # note: diagonal of 'success' is always zero so we can discard it. That's why we divide by len-1\n",
    "    perf = np.mean(success_cnt) / (len(ground_truth)-1)\n",
    "    p = 1 - binom.cdf(perf*len(ground_truth)*(len(ground_truth)-1), len(ground_truth)*(len(ground_truth)-1), 0.5)\n",
    "    \n",
    "    return perf, p\n",
    "\n",
    "def pairwise_corr_individuals(ground_truth, predictions):\n",
    "    r = np.corrcoef(ground_truth, predictions)#cosine_similarity(ground_truth, predictions)#\n",
    "    r = r[:len(ground_truth), len(ground_truth):]  # rows: groundtruth, columns: predicitons\n",
    "    #print(r.shape)\n",
    "    # congruent pairs are on diagonal\n",
    "    congruents = np.diag(r)\n",
    "    #print(congruents)\n",
    "    \n",
    "    # for each column (predicition) we should count the number of rows (groundtruth) that the value is lower than the congruent (e.g. success).\n",
    "    success = r < congruents\n",
    "    success_cnt = np.sum(success, 0)\n",
    "    \n",
    "    # note: diagonal of 'success' is always zero so we can discard it. That's why we divide by len-1\n",
    "    perf = success_cnt / (len(ground_truth)-1)\n",
    "    # p = 1 - binom.cdf(perf*len(ground_truth)*(len(ground_truth)-1), len(ground_truth)*(len(ground_truth)-1), 0.5)\n",
    "    \n",
    "    return perf\n",
    "\n",
    "\n",
    "net_list = [\n",
    "    ('inceptionv3','avgpool'),\n",
    "    ('clip','final'),\n",
    "    ('alexnet',2),\n",
    "    ('alexnet',5),\n",
    "    ('efficientnet','avgpool'),\n",
    "    ('swav','avgpool')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inceptionv3 avgpool\n",
      "clip final\n",
      "alexnet 2\n",
      "alexnet 5\n",
      "efficientnet avgpool\n",
      "distance:  0.9121800053943298\n",
      "swav avgpool\n",
      "distance:  0.5758596473932266\n"
     ]
    }
   ],
   "source": [
    "num_test = 200\n",
    "test_dir = 'cache/thingseeg2_preproc/eval_features/test_images'\n",
    "feats_dir = 'cache/thingseeg2_preproc/eval_features/subj1_preproc_800ms'\n",
    "distance_fn = sp.spatial.distance.correlation\n",
    "pairwise_corrs = []\n",
    "for (net_name,layer) in net_list:\n",
    "    file_name = '{}/{}_{}.npy'.format(test_dir,net_name,layer)\n",
    "    gt_feat = np.load(file_name)\n",
    "    \n",
    "    file_name = '{}/{}_{}.npy'.format(feats_dir,net_name,layer)\n",
    "    eval_feat = np.load(file_name)\n",
    "    \n",
    "    gt_feat = gt_feat.reshape((len(gt_feat),-1))\n",
    "    eval_feat = eval_feat.reshape((len(eval_feat),-1))\n",
    "\n",
    "    print(net_name,layer)\n",
    "    if net_name in ['efficientnet','swav']:\n",
    "        print('distance: ',np.array([distance_fn(gt_feat[i],eval_feat[i]) for i in range(num_test)]).mean())\n",
    "    else:\n",
    "        # pairwise_corrs.append(pairwise_corr_all(gt_feat[:num_test],eval_feat[:num_test])[0])\n",
    "        pairwise_corrs.append(pairwise_corr_individuals(gt_feat[:num_test],eval_feat[:num_test]))\n",
    "        # print('pairwise corr: ',pairwise_corrs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_inds = np.argsort(pairwise_corrs[0])[::-1]\n",
    "clip_inds = np.argsort(pairwise_corrs[1])[::-1]\n",
    "alexnet2_inds = np.argsort(pairwise_corrs[2])[::-1]\n",
    "alexnet5_inds = np.argsort(pairwise_corrs[3])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16540, 17, 80) (200, 17, 80)\n"
     ]
    }
   ],
   "source": [
    "# train_path = 'data/things-eeg2_preproc/sub01/train_thingseeg2_avg_800ms.npy'\n",
    "train_path = 'data/things-eeg2_preproc/train_thingseeg2_avg_800ms.npy'\n",
    "train_eeg = np.load(train_path, mmap_mode='r')\n",
    "# train_eeg_flattened = train_eeg.reshape(train_eeg.shape[0], -1)\n",
    "# test_path = 'data/things-eeg2_preproc/sub01/test_thingseeg2_avg_800ms.npy'\n",
    "test_path = 'data/things-eeg2_preproc/test_thingseeg2_avg_800ms.npy'\n",
    "test_eeg = np.load(test_path, mmap_mode='r')\n",
    "test_eeg = test_eeg[clip_inds]\n",
    "# test_eeg_flattened = test_eeg.reshape(test_eeg.shape[0], -1)\n",
    "print(train_eeg.shape, test_eeg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eeg_0 = test_eeg[0]\n",
    "test_eeg_4 = test_eeg[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 5\n",
    "stride = 1\n",
    "n_examples = 80 - time_window + 1\n",
    "synthetic_eeg_0to4 = np.zeros((n_examples, 17, 80))\n",
    "synthetic_eeg_4to0 = np.zeros((n_examples, 17, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_example in range(n_examples - 1):\n",
    "    synthetic_eeg_0to4[i_example] = test_eeg_4\n",
    "    synthetic_eeg_4to0[i_example] = test_eeg_0\n",
    "    start = i_example * stride\n",
    "    end = start + time_window\n",
    "    synthetic_eeg_0to4[i_example,:, start:end] = test_eeg_0[:, start:end]\n",
    "    synthetic_eeg_4to0[i_example,:, start:end] = test_eeg_4[:, start:end]\n",
    "synthetic_eeg_0to4[-1] = test_eeg_4\n",
    "synthetic_eeg_4to0[-1] = test_eeg_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'cache/thingseeg2_synthetic/'\n",
    "if not os.path.exists(dir):\n",
    "   os.makedirs(dir)\n",
    "np.save(dir + 'sub01_0to4__5_1__800ms.npy', synthetic_eeg_0to4)\n",
    "np.save(dir + 'sub01_4to0__5_1__800ms.npy', synthetic_eeg_4to0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
